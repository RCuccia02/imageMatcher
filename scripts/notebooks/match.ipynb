{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from libraries.Matcher import Matcher\n",
    "from libraries.Detector import Detector\n",
    "from libraries.FileManagerKPDS import FileManagerKPDS as fm\n",
    "from libraries.listdirNoHidden import listdirNoHidden as ldnh\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = '../../datasets/rescaled_dataset/'\n",
    "newDatasetPath = '../../datasets/cropped_dataset/'\n",
    "method = 'ORB'\n",
    "detector = Detector.defineDetector(method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"combined_dataset\", \"zoomed_dataset\", \"downscaled_dataset\", \"gBlur_dataset\", \"gNoise_dataset\", \"hor_dataset\", \"ver_dataset\"]\n",
    "cached_dataset = {}\n",
    "pathList = ldnh(os.path.join(datasetPath, 'images'))\n",
    "\n",
    "for imgPath in pathList:\n",
    "\timgName = os.path.basename(imgPath)\n",
    "\timg1 = cv2.imread(imgPath)\n",
    "\tkp1 = fm.loadKP(datasetPath, imgName, method)\n",
    "\tdes1 = fm.loadDS(datasetPath, imgName, method)\n",
    "\tcached_dataset[imgName] = (img1, kp1, des1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, dictItem in enumerate(cached_dataset.items()):\n",
    "#   imgName = dictItem[0]\n",
    "#   img1, kp1, des1 = dictItem[1]\n",
    "\n",
    "#   #show image\n",
    "#   print(imgName)\n",
    "#   plt.figure(figsize=(20,10))\n",
    "#   plt.imshow(img1)\n",
    "#   plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7GnZoVeGb_20221206_091309.jpg 0.25 0.2\n",
      "3VeDo_photo_2022-10-13_16-17-12.jpg 0.1 0.07142857142857142\n",
      "8GbGn_photo_2022-10-13_16-17-12.jpg 1.0 1.0\n",
      "3GnHoGb_photo_2022-10-13_16-16-46.jpg 0.2 0.2\n",
      "1DoZoHo_20221103_080342.jpg 0.03333333333333333 0.058823529411764705\n",
      "0HoGn_20221206_091312.jpg 0.5 1.0\n",
      "3GnZoVeGb_20221205_122031.jpg 0.07142857142857142 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('all'+method+'1.txt', 'w') as file: \n",
    "\tstartTime = time.time()\n",
    "\ttotImages = 0\n",
    "\tfor dataset in datasets:\n",
    "\t\tnewDatasetPath = '../../datasets/' + dataset + '/'\n",
    "\t\tnewDatasetImagesPaths = ldnh(newDatasetPath)\n",
    "\t\ttotImages += len(newDatasetImagesPaths)\n",
    "\t\tmapArray = []\n",
    "\t\tmapArrayNormalized = []\n",
    "\t\tfor j, newImgPath in enumerate(newDatasetImagesPaths):\n",
    "\t\t\timg2 = cv2.imread(newImgPath)\n",
    "\t\t\tnewImgName = newImgPath.split('/')[-1] #sempre precachabile, ma Ã¨ \"solo\" O(n^2) (stringhe in python sono lente)\n",
    "\t\t\tkp2, des2 = detector.detectAndCompute(img2, None)\n",
    "\t\t\tscores = [None] * len(cached_dataset)\n",
    "\t\t\tnormalizedScores = [None] * len(cached_dataset)\n",
    "\t\t\tfor i, dictItem in enumerate(cached_dataset.items()):\n",
    "\t\t\t\timgName = dictItem[0]\n",
    "\t\t\t\timg1, kp1, des1 = dictItem[1]\n",
    "\t\t\t\ttry: \n",
    "\t\t\t\t\tmatches = Matcher.getMatches(des1, des2,method) \n",
    "\t\t\t\t\tgood, mask = Matcher.lowe(matches,0.7)\n",
    "\t\t\t\t\tscores[i] = (imgName, len(good),  img1, kp1, img2, kp2, matches, mask)\n",
    "\t\t\t\t\tnormalizedScores[i] = (imgName, len(good)/len(matches),  img1, kp1, img2, kp2, matches, mask)\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tscores[i] = (imgName, 0,  img1, kp1, img2, kp2, None, None)\n",
    "\t\t\t\t\tnormalizedScores[i] = (imgName, 0,  img1, kp1, img2, kp2, None, None)\n",
    "\n",
    "\t\t\tscores.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\t\t\tnormalizedScores.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\t\t\t#Matcher.showMatches(scores[0][2], scores[0][3], scores[0][4], scores[0][5], scores[0][6], scores[0][7])\n",
    "\t\t\t#Matcher.showMatches(normalizedScores[0][2], normalizedScores[0][3], normalizedScores[0][4], normalizedScores[0][5], normalizedScores[0][6], normalizedScores[0][7])\n",
    "\n",
    "\t\t\tf0 = 0\n",
    "\t\t\tf1 = 0\n",
    "\t\t\tcombinedTransforms = \"\"\n",
    "\t\t\tif(dataset == 'combined_dataset'):\n",
    "\t\t\t\tsplits = newImgName.split('_', 1)\n",
    "\t\t\t\tcombinedTransforms = splits[0]+\"_\"\n",
    "\t\t\t\tnewImgName = splits[1]\n",
    "\t\t\twhile(not (f1 and f0)):\n",
    "\t\t\t\tfor i in range(len(cached_dataset)):\n",
    "\t\t\t\t\ts = 1/(i+1)\n",
    "\t\t\t\t\tif(scores[i][0] == newImgName):\n",
    "\t\t\t\t\t\tmapArray.append(s)\n",
    "\t\t\t\t\t\tf0 = 1\n",
    "\t\t\t\t\tif(normalizedScores[i][0] == newImgName):\n",
    "\t\t\t\t\t\tmapArrayNormalized.append(s)\n",
    "\t\t\t\t\t\tf1 = 1\n",
    "\t\t\tfile.write(combinedTransforms+newImgName + \" \" + str(mapArray[-1])+ \" \" + str(mapArrayNormalized[-1] )+ \"\\n\") # str(obj) -> obj.__str__()\n",
    "\t\t\tprint(combinedTransforms+newImgName + \" \" +str(mapArray[-1])+\" \"+ str(mapArrayNormalized[-1]))\n",
    "\t\tfile.write(\"MAP: \"+ str(np.mean(mapArray))+ \" Dataset: \"+ dataset+\"\\n\")\n",
    "\t\tprint(\"MAP: \"+ str(np.mean(mapArray))+ \" Dataset: \"+ dataset+\"\\n\")\n",
    "\t\tfile.write(\"MAP Normalized: \"+ str(np.mean(mapArrayNormalized))+ \" Dataset: \"+ dataset+\"\\n\")\n",
    "\t\tprint(\"MAP Normalized: \"+ str(np.mean(mapArrayNormalized))+ \" Dataset: \"+ dataset+\"\\n\")\n",
    "\n",
    "\tstopTime = time.time()\n",
    "\n",
    "\tfile.write(\"Time: \"+ str(stopTime - startTime))\n",
    "\tfile.write(\"Time per query: \"+ str((stopTime - startTime)/totImages))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
